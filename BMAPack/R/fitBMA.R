#' Performs Bayesian Model Averaging (BMA) over entire model space
#' 
#' Performs BMA over entire model space and produces relevant output.
#' 
#' @param M a matrix of observations for the covariates.
#' @param Y a numeric vector whose length is equal to the number of rows of \code{M}.
#' @param gprior a user specified prior.
#' 
#' @return An object of class list with elements
#'  \item{Coeffs}{A matrix of coefficient estimates generated by the regressions of all possible covariate combinations.}
#'  \item{R2s}{A vector of R-squared values generated by the regressions of all possible covariate combinations.}
#'  \item{PosteriorOdds}{The posterior model odds for each model.}
#'  \item{PosteriorValues}{The posterior expected value of each coefficient.}
#'  \item{PosteriorNonZero}{The posterior probability that the coefficient is non-zero.}
#'  @author Dino Hadzic \email{dino.hadzic@@wustl.edu}
#'  @examples
#'  
#'  M <- matrix(rnorm(30), ncol=3)
#'  Y <- c(rnorm(10))
#'  fitBMA(M, Y, gprior=3)
#'  @seealso \code{\link{plotBMA}}
#'  @rdname fitBMA
#'  @aliases fitBMA,ANY-method
#'  @export
fitBMA <- function(M, Y, gprior){ #Function takes as arguments matrix M, vector Y, and user specified gprior
  R2s <- numeric()
  M <- scale(M) #Standardizes the matrix of covariate observations.
  Y <- scale(Y) #Standardizes the vector of dependent variable outcomes.
  coefs <- matrix(NA, nrow=ncol(M)) #Creates a 1 column matrix of NAs.
  
  #These for loops generate all possible models in the model space. We begin by generating all possible
  #combinations of covariates and then peform the linear regressions. In order to remove the intercept term,
  #we subtract 1 in the linear model. From here, we extract the R-squared values and the coefficients and store them as
  #R2s and coefs.
  for(i in 1:ncol(M)){ 
    combos <- combn(1:ncol(M), i)
    for(j in 1:ncol(combos)){
      lm1 <- numeric(ncol(M))
      lm1[c(combos[,j])] <- lm(Y ~ M[,combos[,j]] - 1)[["coefficients"]]
      R2s <- c(R2s, summary(lm(Y ~ M[,combos[,j]]))[["r.squared"]])   
      coefs <- cbind(coefs, lm1)
    }
  }
  #Conversts R2s into a matrix of one row that stores the R-squared values horizontally. Also, we
  #remove the unnecessary first column of coefs.
  R2s <- matrix(R2s, ncol=length(R2s))
  coefs <- coefs[,-1]
  
  #Utilizing the user selected value for the gprior, we calculate with the code below 
  #B[M_k : M_0]. We will need this for the next section, in which we calculate the posterior 
  #probabilities. Store output as BMM.
  BMM <- numeric()
  for(z in 1:ncol(coefs)){
    BMM[z] <- (1 + gprior)^((nrow(M)-ncol(M))/2) * (1 + gprior*(1 - R2s[z]))^(-(nrow(M)-1)/2)
  }  
  
  #The code below calculates the posterior model odds and converts the object Posterior
  #into a matrix.
  Posterior <- numeric()
  for(u in 1:length(BMM)){
    Posterior[u] <- BMM[u]/sum(BMM)
  }
  Posterior <- matrix(Posterior, ncol=length(Posterior))
  
  #Now, using the coefficients from all possible models and gprior that was specified by the user,
  #we calculate E(B_k | M_k). We will need this for the next part, where we calculcate the posterior
  #expected value of each coefficient. Store output as EBM.
  EBM <- matrix(ncol=ncol(coefs), nrow=nrow(coefs))
  for(i in 1:ncol(coefs)){
    EBM[,i] <- (gprior/(gprior+1))*coefs[,i]
  } 
  
  #Object Expect_B is assigned the posterior expected values of each coefficient and then the object
  #converted into a matrix. To calculate this, we sum the product of the posterior model probability and 
  #EBM for each model and store it as an object, Expect_B.
  Expect_B <- numeric()
  for(l in 1:nrow(EBM)){
    Expect_B[l] <- sum(Posterior[l]*EBM[l,])
  }
  Expect_B <- as.matrix(Expect_B)
  
  #This last calculation involves finding the posterior probability that a particular coefficient is
  #non-zero. This is the total weight assigned to all models that include coefficient i. We simply
  #extract those posterior model odds for which a coefficient is not zero for each row of the 
  #coefficient output, and then sum up those probabilities.
  Prob_non_0 <- numeric()
  for(i in 1:nrow(coefs)){
    Prob_non_0[i] <- sum(Posterior[coefs[i,] != 0])
  }
  Prob_non_0 <- matrix(Prob_non_0, byrow=TRUE)
  
  #The code below assigns appropriate column and row names to every required output, including 
  #all of the coefficients, all of the R-squared values, the posterior model odds of each model,
  #the posterior expected value of each coefficient, and the posterior probability that the 
  #coefficient is non-zero.
  colnames(coefs) <- paste("Model", 1:(ncol(coefs)))
  rownames(coefs) <- paste("Coefficient", 1:(nrow(coefs)))
  colnames(R2s) <- paste("Model", 1:ncol(R2s))
  rownames(R2s) <- "R-squared"
  colnames(Posterior) <- paste("Model", 1:(ncol(Posterior)))
  rownames(Posterior) <- "Probability"
  colnames(Expect_B) <- "Value"
  rownames(Expect_B) <- paste("Coefficient", 1:(nrow(Expect_B)))
  colnames(Prob_non_0) <- "Probability"
  rownames(Prob_non_0) <- paste("Coefficient", 1:(nrow(Prob_non_0)))
  
  #Finally, we specify that the function should return an object of class list that includes the
  #relevant information.
  return(list("Coeffs"=coefs, "R2s"=R2s, "PosteriorOdds"=Posterior, "PosteriorValues"=Expect_B, 
              "PosteriorNonZero" = Prob_non_0)) 
}